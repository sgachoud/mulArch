# Implemented Algorithm
## pi.c double calculate_pi(...)

## integral.c double integrate(...)
### a.
This function is divided into 3 phases:
The _first phase_ is sequencial and is meant to initialize common variables. The variable 'in' which is meant to recieve the sum of the separate work done by each thread an the variable 'l' which is just a common shared value (the length of the interval to integrate).

The _second phase_ is parallel. Each iteration of the loop is independent from the others and can therefore be treated by diffrent threads. Each thread generate its own random generator so they can freely access. A shared random generator would produce latency or multiple use of the same random value. To avoid slowing down threads with atomic access to 'in', each one of them have its own 'sum' variable to store all area calculated by the loop iterations. Finaly each thread adds atomicaly its part of the work inside 'in' to avoid concurrent access resulting in loss of data.

The _third phase_ is sequencial and just meant to calculate the integral and return the result.

### b.
The _first phase_ is limited by the substracion for 'l' (b-a) or the creation of the threads if we consider that it belongs to the _first phase_.

The _second phase_ is limited by the for loop and inside the loop, the random number generation.

The _third phase_ is limited by the division or maybe the destruction of the threads if it is considered as part of this phase.

### c.
The _first phase_ is not affected by the arguments. O(1)
Or by the number of thread O(numThreads).

The _second phase_ is affected by the arguments since the loop depends linearly of the number of samples. O(samples)

### d.
Since the sequencial phases are really short for a big number of samples, almost the whole program can be speed up by adding threads. We can assume that the parallel phase is big enough compared to the sequencial phases to ignore the runtime of the sequential phases. Therefore in a perfect world doubling the number of cores would mean dividing the runtime by 2.
Therefore the speedup is roughly equal to the number of cores.